{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c81279e-a568-4e36-9906-06317accb622",
   "metadata": {},
   "source": [
    "# Train CLMBR\n",
    "\n",
    "This tutorial walks through the various steps to train a CLMBR model.\n",
    "\n",
    "Note that CLMBR requires the gpu enabled version of FEMR. See the [README](https://github.com/som-shahlab/femr#how-to-install-femr-with-cuda-support) for the relevant instructions.\n",
    "\n",
    "Training CLMBR is a three step process:\n",
    "\n",
    "- Generating a dictionary\n",
    "- Creating batches\n",
    "- Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dcdfd70-58a1-4460-80a8-db737a8c5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "TARGET_DIR = 'trash/tutorial_5'\n",
    "\n",
    "if os.path.exists(TARGET_DIR):\n",
    "    shutil.rmtree(TARGET_DIR)\n",
    "\n",
    "os.mkdir(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60ab7df-e851-44a5-ab70-7bee292be00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banned 0 out of 4523\n",
      "Got age statistics ... {\"mean\":834488.8237272066,\"std\":1516971.4691312015}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "EXTRACT_LOCATION = \"input/extract\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The first step of training CLMBR is creating a dictionary, that helps map codes to integers that can be used within a neural network.\n",
    "\"\"\"\n",
    "\n",
    "DICTIONARY_PATH = os.path.join(TARGET_DIR, \"dictionary\")\n",
    "os.system(f\"clmbr_create_dictionary {DICTIONARY_PATH} --data_path {EXTRACT_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89611ba9-a242-4b87-9b8f-25670d838fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped When mapping codes, dropped 0 out of 0 out of 2048\n",
      "2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n",
      "When mapping codes, dropped 0 out of 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 12:30:22,260 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='trash/tutorial_5/clmbr_batches', data_path='input/extract', dictionary_path='trash/tutorial_5/dictionary', task='clmbr', transformer_vocab_size=2048, clmbr_survival_dictionary_path=None, labeled_patients_path=None, is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None, num_clmbr_tasks=8192)\n",
      "2024-01-12 12:30:22,284 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2024-01-12 12:30:22,284 [MainThread  ] [INFO ]  Starting to load\n",
      "2024-01-12 12:30:22,360 [MainThread  ] [INFO ]  Loaded\n",
      "2024-01-12 12:30:22,393 [MainThread  ] [INFO ]  Number of train patients 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The second step of training CLMBR is to prepare the batches that will actually get fed into the neural network.\n",
    "\"\"\"\n",
    "\n",
    "CLMBR_BATCHES = os.path.join(TARGET_DIR, \"clmbr_batches\")\n",
    "\n",
    "os.system(\n",
    "    f\"clmbr_create_batches {CLMBR_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task clmbr --transformer_vocab_size 2048\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f654a46c-5aa7-465c-b6c5-73d8ba26ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ripplekhera/code/venvs/femr_venv/bin/clmbr_train_model\", line 8, in <module>\n",
      "    sys.exit(train_model())\n",
      "  File \"/Users/ripplekhera/code/femr/src/femr/models/scripts.py\", line 92, in train_model\n",
      "    os.mkdir(args.directory)\n",
      "FileExistsError: [Errno 17] File exists: 'trash/tutorial_5/clmbr_model'\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mGiven the batches, it is now possible to train CLMBR. By default it will train for 100 epochs, with early stopping.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m MODEL_PATH \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(TARGET_DIR, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclmbr_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39msystem(\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclmbr_train_model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMODEL_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m --data_path \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEXTRACT_LOCATION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m --batches_path \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCLMBR_BATCHES\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m --learning_rate 1e-4 --rotary_type per_head --num_batch_threads 3 --max_iter 10 --n_layers 1 --hidden_size 256 --n_heads 4 --intermediate_size 256\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     10\u001B[0m )\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the batches, it is now possible to train CLMBR. By default it will train for 100 epochs, with early stopping.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_PATH = os.path.join(TARGET_DIR, \"clmbr_model\")\n",
    "\n",
    "\n",
    "assert 0 == os.system(\n",
    "    f\"clmbr_train_model {MODEL_PATH} --data_path {EXTRACT_LOCATION} --batches_path {CLMBR_BATCHES} --learning_rate 1e-4 --rotary_type per_head --num_batch_threads 3 --max_iter 10 --n_layers 1 --hidden_size 256 --n_heads 4 --intermediate_size 256\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e6287-5fff-4c50-b517-587d9e088dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}